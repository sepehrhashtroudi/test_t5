10/29/2022 23:17:30 - INFO - __main__ -   Namespace(task='concode', sub_task='none', lang='java', eval_task='', model_type='codet5', add_lang_ids=False, data_num=500, start_epoch=0, num_train_epochs=1, patience=3, cache_path='saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/cache_data', summary_dir='tensorboard', data_dir='../data', res_dir='saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/prediction', res_fn='results/concode_codet5_base.txt', add_task_prefix=False, save_last_checkpoints=True, always_save_model=True, do_eval_bleu=True, model_name_or_path='../pretrained_models/codet5-base', output_dir='saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10', load_model_path=None, train_filename=None, dev_filename=None, test_filename=None, config_name='', tokenizer_name='../pretrained_models/codet5-base', max_source_length=320, max_target_length=320, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=0.0001, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, save_steps=-1, log_steps=-1, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=1000, local_rank=-1, seed=1234)
10/29/2022 23:17:31 - WARNING - configs -   Process rank: -1, device: cuda, n_gpu: 4, distributed training: False, cpu count: 40
10/29/2022 23:17:38 - INFO - models -   Finish loading model [223M] from ../pretrained_models/codet5-base
10/29/2022 23:17:43 - INFO - utils -   train_fn
10/29/2022 23:17:43 - INFO - utils -   ../data/methods2test/corpus/raw/fm_fc_ms_ff/train/input.methods.txt,../data/methods2test/corpus/raw/fm_fc_ms_ff/train/output.tests.txt
10/29/2022 23:17:43 - INFO - utils -   train_fn
10/29/2022 23:17:45 - INFO - utils -   Read 500 examples, avg src len: 158, avg trg len: 39, max src len: 1004, max trg len: 406
10/29/2022 23:17:45 - INFO - utils -   [TOKENIZE] avg src len: 451, avg trg len: 149, max src len: 3108, max trg len: 1578
10/29/2022 23:17:45 - INFO - utils -   Create cache data into saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/cache_data/train_500.pt
  0%|          | 0/500 [00:00<?, ?it/s]  3%|▎         | 16/500 [00:00<00:03, 132.12it/s]  6%|▋         | 32/500 [00:00<00:03, 138.55it/s] 10%|▉         | 48/500 [00:00<00:03, 140.62it/s] 13%|█▎        | 64/500 [00:00<00:03, 141.41it/s] 16%|█▌        | 80/500 [00:00<00:02, 141.95it/s] 19%|█▉        | 96/500 [00:00<00:02, 141.78it/s] 22%|██▏       | 112/500 [00:00<00:02, 142.14it/s] 26%|██▌       | 128/500 [00:00<00:02, 142.21it/s] 29%|██▉       | 144/500 [00:01<00:02, 142.26it/s] 32%|███▏      | 160/500 [00:01<00:02, 141.64it/s] 35%|███▌      | 176/500 [00:01<00:02, 144.34it/s] 38%|███▊      | 192/500 [00:01<00:02, 145.64it/s] 42%|████▏     | 208/500 [00:01<00:01, 147.17it/s] 45%|████▍     | 224/500 [00:01<00:01, 148.89it/s] 48%|████▊     | 240/500 [00:01<00:01, 149.16it/s] 51%|█████     | 256/500 [00:01<00:01, 150.30it/s] 54%|█████▍    | 272/500 [00:01<00:01, 145.89it/s] 58%|█████▊    | 288/500 [00:01<00:01, 145.08it/s] 61%|██████    | 304/500 [00:02<00:01, 144.13it/s] 64%|██████▍   | 320/500 [00:02<00:01, 143.86it/s] 67%|██████▋   | 336/500 [00:02<00:01, 144.27it/s] 70%|███████   | 352/500 [00:02<00:01, 145.06it/s] 74%|███████▎  | 368/500 [00:02<00:00, 147.10it/s] 77%|███████▋  | 384/500 [00:02<00:00, 146.24it/s] 80%|████████  | 400/500 [00:02<00:00, 144.44it/s] 83%|████████▎ | 416/500 [00:02<00:00, 144.88it/s] 86%|████████▋ | 432/500 [00:02<00:00, 145.49it/s] 90%|████████▉ | 448/500 [00:03<00:00, 147.27it/s] 93%|█████████▎| 464/500 [00:03<00:00, 144.74it/s] 96%|█████████▌| 480/500 [00:03<00:00, 147.26it/s] 99%|█████████▉| 496/500 [00:03<00:00, 147.56it/s]100%|██████████| 500/500 [00:03<00:00, 144.89it/s]
/home/sepehr8/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
10/29/2022 23:17:49 - INFO - __main__ -   ***** Running training *****
10/29/2022 23:17:49 - INFO - __main__ -     Num examples = 500
10/29/2022 23:17:49 - INFO - __main__ -     Batch size = 8
10/29/2022 23:17:49 - INFO - __main__ -     Batch num = 63
10/29/2022 23:17:49 - INFO - __main__ -     Num epoch = 1
Training:   0%|          | 0/63 [00:00<?, ?it/s]/home/sepehr8/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
[0] Train loss 1.772:   0%|          | 0/63 [00:08<?, ?it/s][0] Train loss 1.772:   2%|▏         | 1/63 [00:08<08:24,  8.14s/it][0] Train loss 1.969:   2%|▏         | 1/63 [00:08<08:24,  8.14s/it][0] Train loss 1.969:   3%|▎         | 2/63 [00:08<03:36,  3.56s/it][0] Train loss 2.068:   3%|▎         | 2/63 [00:08<03:36,  3.56s/it][0] Train loss 2.068:   5%|▍         | 3/63 [00:08<02:03,  2.07s/it][0] Train loss 2.142:   5%|▍         | 3/63 [00:09<02:03,  2.07s/it][0] Train loss 2.142:   6%|▋         | 4/63 [00:09<01:20,  1.37s/it][0] Train loss 2.185:   6%|▋         | 4/63 [00:09<01:20,  1.37s/it][0] Train loss 2.185:   8%|▊         | 5/63 [00:09<00:56,  1.02it/s][0] Train loss 2.165:   8%|▊         | 5/63 [00:09<00:56,  1.02it/s][0] Train loss 2.165:  10%|▉         | 6/63 [00:09<00:42,  1.34it/s][0] Train loss 2.167:  10%|▉         | 6/63 [00:09<00:42,  1.34it/s][0] Train loss 2.167:  11%|█         | 7/63 [00:09<00:34,  1.64it/s][0] Train loss 2.083:  11%|█         | 7/63 [00:10<00:34,  1.64it/s][0] Train loss 2.083:  13%|█▎        | 8/63 [00:10<00:27,  1.97it/s][0] Train loss 2.272:  13%|█▎        | 8/63 [00:10<00:27,  1.97it/s][0] Train loss 2.272:  14%|█▍        | 9/63 [00:10<00:23,  2.27it/s][0] Train loss 2.339:  14%|█▍        | 9/63 [00:10<00:23,  2.27it/s][0] Train loss 2.339:  16%|█▌        | 10/63 [00:10<00:20,  2.54it/s][0] Train loss 2.372:  16%|█▌        | 10/63 [00:11<00:20,  2.54it/s][0] Train loss 2.372:  17%|█▋        | 11/63 [00:11<00:18,  2.77it/s][0] Train loss 2.326:  17%|█▋        | 11/63 [00:11<00:18,  2.77it/s][0] Train loss 2.326:  19%|█▉        | 12/63 [00:11<00:17,  2.94it/s][0] Train loss 2.378:  19%|█▉        | 12/63 [00:11<00:17,  2.94it/s][0] Train loss 2.378:  21%|██        | 13/63 [00:11<00:16,  2.97it/s][0] Train loss 2.367:  21%|██        | 13/63 [00:12<00:16,  2.97it/s][0] Train loss 2.367:  22%|██▏       | 14/63 [00:12<00:15,  3.10it/s][0] Train loss 2.383:  22%|██▏       | 14/63 [00:12<00:15,  3.10it/s][0] Train loss 2.383:  24%|██▍       | 15/63 [00:12<00:15,  3.20it/s][0] Train loss 2.394:  24%|██▍       | 15/63 [00:12<00:15,  3.20it/s][0] Train loss 2.394:  25%|██▌       | 16/63 [00:12<00:14,  3.27it/s][0] Train loss 2.342:  25%|██▌       | 16/63 [00:12<00:14,  3.27it/s][0] Train loss 2.342:  27%|██▋       | 17/63 [00:12<00:13,  3.32it/s][0] Train loss 2.336:  27%|██▋       | 17/63 [00:13<00:13,  3.32it/s][0] Train loss 2.336:  29%|██▊       | 18/63 [00:13<00:13,  3.22it/s][0] Train loss 2.285:  29%|██▊       | 18/63 [00:13<00:13,  3.22it/s][0] Train loss 2.285:  30%|███       | 19/63 [00:13<00:13,  3.27it/s][0] Train loss 2.296:  30%|███       | 19/63 [00:13<00:13,  3.27it/s][0] Train loss 2.296:  32%|███▏      | 20/63 [00:13<00:12,  3.31it/s][0] Train loss 2.295:  32%|███▏      | 20/63 [00:14<00:12,  3.31it/s][0] Train loss 2.295:  33%|███▎      | 21/63 [00:14<00:12,  3.35it/s][0] Train loss 2.261:  33%|███▎      | 21/63 [00:14<00:12,  3.35it/s][0] Train loss 2.261:  35%|███▍      | 22/63 [00:14<00:12,  3.38it/s][0] Train loss 2.256:  35%|███▍      | 22/63 [00:14<00:12,  3.38it/s][0] Train loss 2.256:  37%|███▋      | 23/63 [00:14<00:11,  3.39it/s][0] Train loss 2.256:  37%|███▋      | 23/63 [00:15<00:11,  3.39it/s][0] Train loss 2.256:  38%|███▊      | 24/63 [00:15<00:12,  3.21it/s][0] Train loss 2.256:  38%|███▊      | 24/63 [00:15<00:12,  3.21it/s][0] Train loss 2.256:  40%|███▉      | 25/63 [00:15<00:11,  3.28it/s][0] Train loss 2.276:  40%|███▉      | 25/63 [00:15<00:11,  3.28it/s][0] Train loss 2.276:  41%|████▏     | 26/63 [00:15<00:11,  3.33it/s][0] Train loss 2.249:  41%|████▏     | 26/63 [00:15<00:11,  3.33it/s][0] Train loss 2.249:  43%|████▎     | 27/63 [00:15<00:10,  3.37it/s][0] Train loss 2.276:  43%|████▎     | 27/63 [00:16<00:10,  3.37it/s][0] Train loss 2.276:  44%|████▍     | 28/63 [00:16<00:10,  3.39it/s][0] Train loss 2.263:  44%|████▍     | 28/63 [00:16<00:10,  3.39it/s][0] Train loss 2.263:  46%|████▌     | 29/63 [00:16<00:09,  3.41it/s][0] Train loss 2.245:  46%|████▌     | 29/63 [00:16<00:09,  3.41it/s][0] Train loss 2.245:  48%|████▊     | 30/63 [00:16<00:10,  3.28it/s][0] Train loss 2.24:  48%|████▊     | 30/63 [00:17<00:10,  3.28it/s] [0] Train loss 2.24:  49%|████▉     | 31/63 [00:17<00:09,  3.32it/s][0] Train loss 2.249:  49%|████▉     | 31/63 [00:17<00:09,  3.32it/s][0] Train loss 2.249:  51%|█████     | 32/63 [00:17<00:09,  3.36it/s][0] Train loss 2.238:  51%|█████     | 32/63 [00:17<00:09,  3.36it/s][0] Train loss 2.238:  52%|█████▏    | 33/63 [00:17<00:08,  3.39it/s][0] Train loss 2.211:  52%|█████▏    | 33/63 [00:18<00:08,  3.39it/s][0] Train loss 2.211:  54%|█████▍    | 34/63 [00:18<00:08,  3.38it/s][0] Train loss 2.184:  54%|█████▍    | 34/63 [00:18<00:08,  3.38it/s][0] Train loss 2.184:  56%|█████▌    | 35/63 [00:18<00:08,  3.40it/s][0] Train loss 2.172:  56%|█████▌    | 35/63 [00:18<00:08,  3.40it/s][0] Train loss 2.172:  57%|█████▋    | 36/63 [00:18<00:08,  3.24it/s][0] Train loss 2.157:  57%|█████▋    | 36/63 [00:18<00:08,  3.24it/s][0] Train loss 2.157:  59%|█████▊    | 37/63 [00:18<00:07,  3.30it/s][0] Train loss 2.168:  59%|█████▊    | 37/63 [00:19<00:07,  3.30it/s][0] Train loss 2.168:  60%|██████    | 38/63 [00:19<00:07,  3.34it/s][0] Train loss 2.173:  60%|██████    | 38/63 [00:19<00:07,  3.34it/s][0] Train loss 2.173:  62%|██████▏   | 39/63 [00:19<00:07,  3.37it/s][0] Train loss 2.16:  62%|██████▏   | 39/63 [00:19<00:07,  3.37it/s] [0] Train loss 2.16:  63%|██████▎   | 40/63 [00:19<00:06,  3.38it/s][0] Train loss 2.143:  63%|██████▎   | 40/63 [00:20<00:06,  3.38it/s][0] Train loss 2.143:  65%|██████▌   | 41/63 [00:20<00:06,  3.38it/s][0] Train loss 2.136:  65%|██████▌   | 41/63 [00:20<00:06,  3.38it/s][0] Train loss 2.136:  67%|██████▋   | 42/63 [00:20<00:06,  3.24it/s][0] Train loss 2.134:  67%|██████▋   | 42/63 [00:20<00:06,  3.24it/s][0] Train loss 2.134:  68%|██████▊   | 43/63 [00:20<00:06,  3.29it/s][0] Train loss 2.13:  68%|██████▊   | 43/63 [00:21<00:06,  3.29it/s] [0] Train loss 2.13:  70%|██████▉   | 44/63 [00:21<00:05,  3.34it/s][0] Train loss 2.144:  70%|██████▉   | 44/63 [00:21<00:05,  3.34it/s][0] Train loss 2.144:  71%|███████▏  | 45/63 [00:21<00:05,  3.37it/s][0] Train loss 2.131:  71%|███████▏  | 45/63 [00:21<00:05,  3.37it/s][0] Train loss 2.131:  73%|███████▎  | 46/63 [00:21<00:05,  3.39it/s][0] Train loss 2.109:  73%|███████▎  | 46/63 [00:21<00:05,  3.39it/s][0] Train loss 2.109:  75%|███████▍  | 47/63 [00:21<00:04,  3.28it/s][0] Train loss 2.085:  75%|███████▍  | 47/63 [00:22<00:04,  3.28it/s][0] Train loss 2.085:  76%|███████▌  | 48/63 [00:22<00:04,  3.33it/s][0] Train loss 2.071:  76%|███████▌  | 48/63 [00:22<00:04,  3.33it/s][0] Train loss 2.071:  78%|███████▊  | 49/63 [00:22<00:04,  3.36it/s][0] Train loss 2.06:  78%|███████▊  | 49/63 [00:22<00:04,  3.36it/s] [0] Train loss 2.06:  79%|███████▉  | 50/63 [00:22<00:03,  3.39it/s][0] Train loss 2.063:  79%|███████▉  | 50/63 [00:23<00:03,  3.39it/s][0] Train loss 2.063:  81%|████████  | 51/63 [00:23<00:03,  3.40it/s][0] Train loss 2.055:  81%|████████  | 51/63 [00:23<00:03,  3.40it/s][0] Train loss 2.055:  83%|████████▎ | 52/63 [00:23<00:03,  3.41it/s][0] Train loss 2.046:  83%|████████▎ | 52/63 [00:23<00:03,  3.41it/s][0] Train loss 2.046:  84%|████████▍ | 53/63 [00:23<00:03,  3.24it/s][0] Train loss 2.041:  84%|████████▍ | 53/63 [00:24<00:03,  3.24it/s][0] Train loss 2.041:  86%|████████▌ | 54/63 [00:24<00:02,  3.30it/s][0] Train loss 2.047:  86%|████████▌ | 54/63 [00:24<00:02,  3.30it/s][0] Train loss 2.047:  87%|████████▋ | 55/63 [00:24<00:02,  3.34it/s][0] Train loss 2.044:  87%|████████▋ | 55/63 [00:24<00:02,  3.34it/s][0] Train loss 2.044:  89%|████████▉ | 56/63 [00:24<00:02,  3.38it/s][0] Train loss 2.039:  89%|████████▉ | 56/63 [00:24<00:02,  3.38it/s][0] Train loss 2.039:  90%|█████████ | 57/63 [00:24<00:01,  3.40it/s][0] Train loss 2.025:  90%|█████████ | 57/63 [00:25<00:01,  3.40it/s][0] Train loss 2.025:  92%|█████████▏| 58/63 [00:25<00:01,  3.42it/s][0] Train loss 2.012:  92%|█████████▏| 58/63 [00:25<00:01,  3.42it/s][0] Train loss 2.012:  94%|█████████▎| 59/63 [00:25<00:01,  3.29it/s][0] Train loss 2.003:  94%|█████████▎| 59/63 [00:25<00:01,  3.29it/s][0] Train loss 2.003:  95%|█████████▌| 60/63 [00:25<00:00,  3.34it/s][0] Train loss 1.994:  95%|█████████▌| 60/63 [00:26<00:00,  3.34it/s][0] Train loss 1.994:  97%|█████████▋| 61/63 [00:26<00:00,  3.37it/s][0] Train loss 1.983:  97%|█████████▋| 61/63 [00:26<00:00,  3.37it/s][0] Train loss 1.983:  98%|█████████▊| 62/63 [00:26<00:00,  3.40it/s][0] Train loss 1.993:  98%|█████████▊| 62/63 [00:27<00:00,  3.40it/s][0] Train loss 1.993: 100%|██████████| 63/63 [00:27<00:00,  2.54it/s][0] Train loss 1.993: 100%|██████████| 63/63 [00:27<00:00,  2.33it/s]
10/29/2022 23:18:17 - INFO - utils -   Read 500 examples, avg src len: 98, avg trg len: 35, max src len: 622, max trg len: 193
10/29/2022 23:18:17 - INFO - utils -   Create cache data into saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/cache_data/dev_500.pt
  0%|          | 0/500 [00:00<?, ?it/s]  3%|▎         | 16/500 [00:00<00:03, 134.04it/s]  6%|▋         | 32/500 [00:00<00:03, 142.26it/s] 10%|▉         | 48/500 [00:00<00:03, 146.67it/s] 13%|█▎        | 64/500 [00:00<00:02, 148.86it/s] 16%|█▌        | 80/500 [00:00<00:02, 150.02it/s] 19%|█▉        | 96/500 [00:00<00:02, 149.25it/s] 22%|██▏       | 112/500 [00:00<00:02, 150.10it/s] 26%|██▌       | 128/500 [00:00<00:02, 151.21it/s] 29%|██▉       | 144/500 [00:00<00:02, 151.84it/s] 32%|███▏      | 160/500 [00:01<00:02, 152.30it/s] 35%|███▌      | 176/500 [00:01<00:02, 152.31it/s] 38%|███▊      | 192/500 [00:01<00:02, 152.85it/s] 42%|████▏     | 208/500 [00:01<00:01, 152.89it/s] 45%|████▍     | 224/500 [00:01<00:01, 152.29it/s] 48%|████▊     | 240/500 [00:01<00:01, 152.62it/s] 51%|█████     | 256/500 [00:01<00:01, 152.83it/s] 54%|█████▍    | 272/500 [00:01<00:01, 153.29it/s] 58%|█████▊    | 288/500 [00:01<00:01, 153.72it/s] 61%|██████    | 304/500 [00:02<00:01, 153.87it/s] 64%|██████▍   | 320/500 [00:02<00:01, 153.56it/s] 67%|██████▋   | 336/500 [00:02<00:01, 153.97it/s] 70%|███████   | 352/500 [00:02<00:00, 153.89it/s] 74%|███████▎  | 368/500 [00:02<00:00, 153.38it/s] 77%|███████▋  | 384/500 [00:02<00:00, 153.84it/s] 80%|████████  | 400/500 [00:02<00:00, 154.14it/s] 83%|████████▎ | 416/500 [00:02<00:00, 154.38it/s] 86%|████████▋ | 432/500 [00:02<00:00, 154.49it/s] 90%|████████▉ | 448/500 [00:02<00:00, 154.53it/s] 93%|█████████▎| 464/500 [00:03<00:00, 154.34it/s] 96%|█████████▌| 480/500 [00:03<00:00, 154.37it/s] 99%|█████████▉| 496/500 [00:03<00:00, 153.98it/s]100%|██████████| 500/500 [00:03<00:00, 152.44it/s]
10/29/2022 23:18:20 - INFO - __main__ -     ***** Running ppl evaluation *****
10/29/2022 23:18:20 - INFO - __main__ -     Num examples = 500
10/29/2022 23:18:20 - INFO - __main__ -     Batch size = 8
Eval ppl:   0%|          | 0/63 [00:00<?, ?it/s]Eval ppl:   2%|▏         | 1/63 [00:00<00:24,  2.50it/s]Eval ppl:   3%|▎         | 2/63 [00:00<00:18,  3.34it/s]Eval ppl:   5%|▍         | 3/63 [00:00<00:14,  4.18it/s]Eval ppl:   6%|▋         | 4/63 [00:00<00:12,  4.75it/s]Eval ppl:   8%|▊         | 5/63 [00:01<00:11,  5.14it/s]Eval ppl:  10%|▉         | 6/63 [00:01<00:10,  5.41it/s]Eval ppl:  11%|█         | 7/63 [00:01<00:10,  5.59it/s]Eval ppl:  13%|█▎        | 8/63 [00:01<00:09,  5.71it/s]Eval ppl:  14%|█▍        | 9/63 [00:01<00:09,  5.43it/s]Eval ppl:  16%|█▌        | 10/63 [00:01<00:09,  5.60it/s]Eval ppl:  17%|█▋        | 11/63 [00:02<00:09,  5.71it/s]Eval ppl:  19%|█▉        | 12/63 [00:02<00:08,  5.79it/s]Eval ppl:  21%|██        | 13/63 [00:02<00:08,  5.87it/s]Eval ppl:  22%|██▏       | 14/63 [00:02<00:08,  5.91it/s]Eval ppl:  24%|██▍       | 15/63 [00:02<00:08,  5.56it/s]Eval ppl:  25%|██▌       | 16/63 [00:03<00:08,  5.70it/s]Eval ppl:  27%|██▋       | 17/63 [00:03<00:07,  5.78it/s]Eval ppl:  29%|██▊       | 18/63 [00:03<00:07,  5.85it/s]Eval ppl:  30%|███       | 19/63 [00:03<00:07,  5.89it/s]Eval ppl:  32%|███▏      | 20/63 [00:03<00:07,  5.92it/s]Eval ppl:  33%|███▎      | 21/63 [00:03<00:07,  5.95it/s]Eval ppl:  35%|███▍      | 22/63 [00:04<00:07,  5.56it/s]Eval ppl:  37%|███▋      | 23/63 [00:04<00:07,  5.66it/s]Eval ppl:  38%|███▊      | 24/63 [00:04<00:06,  5.72it/s]Eval ppl:  40%|███▉      | 25/63 [00:04<00:06,  5.77it/s]Eval ppl:  41%|████▏     | 26/63 [00:04<00:06,  5.81it/s]Eval ppl:  43%|████▎     | 27/63 [00:04<00:06,  5.85it/s]Eval ppl:  44%|████▍     | 28/63 [00:05<00:05,  5.89it/s]Eval ppl:  46%|████▌     | 29/63 [00:05<00:06,  5.54it/s]Eval ppl:  48%|████▊     | 30/63 [00:05<00:05,  5.66it/s]Eval ppl:  49%|████▉     | 31/63 [00:05<00:05,  5.76it/s]Eval ppl:  51%|█████     | 32/63 [00:05<00:05,  5.83it/s]Eval ppl:  52%|█████▏    | 33/63 [00:05<00:05,  5.88it/s]Eval ppl:  54%|█████▍    | 34/63 [00:06<00:04,  5.91it/s]Eval ppl:  56%|█████▌    | 35/63 [00:06<00:04,  5.94it/s]Eval ppl:  57%|█████▋    | 36/63 [00:06<00:04,  5.58it/s]Eval ppl:  59%|█████▊    | 37/63 [00:06<00:04,  5.70it/s]Eval ppl:  60%|██████    | 38/63 [00:06<00:04,  5.78it/s]Eval ppl:  62%|██████▏   | 39/63 [00:07<00:04,  5.85it/s]Eval ppl:  63%|██████▎   | 40/63 [00:07<00:03,  5.90it/s]Eval ppl:  65%|██████▌   | 41/63 [00:07<00:03,  5.93it/s]Eval ppl:  67%|██████▋   | 42/63 [00:07<00:03,  5.94it/s]Eval ppl:  68%|██████▊   | 43/63 [00:07<00:03,  5.58it/s]Eval ppl:  70%|██████▉   | 44/63 [00:07<00:03,  5.70it/s]Eval ppl:  71%|███████▏  | 45/63 [00:08<00:03,  5.79it/s]Eval ppl:  73%|███████▎  | 46/63 [00:08<00:02,  5.85it/s]Eval ppl:  75%|███████▍  | 47/63 [00:08<00:02,  5.91it/s]Eval ppl:  76%|███████▌  | 48/63 [00:08<00:02,  5.94it/s]Eval ppl:  78%|███████▊  | 49/63 [00:08<00:02,  5.95it/s]Eval ppl:  79%|███████▉  | 50/63 [00:08<00:02,  5.57it/s]Eval ppl:  81%|████████  | 51/63 [00:09<00:02,  5.69it/s]Eval ppl:  83%|████████▎ | 52/63 [00:09<00:01,  5.78it/s]Eval ppl:  84%|████████▍ | 53/63 [00:09<00:01,  5.85it/s]Eval ppl:  86%|████████▌ | 54/63 [00:09<00:01,  5.90it/s]Eval ppl:  87%|████████▋ | 55/63 [00:09<00:01,  5.93it/s]Eval ppl:  89%|████████▉ | 56/63 [00:09<00:01,  5.95it/s]Eval ppl:  90%|█████████ | 57/63 [00:10<00:01,  5.60it/s]Eval ppl:  92%|█████████▏| 58/63 [00:10<00:00,  5.72it/s]Eval ppl:  94%|█████████▎| 59/63 [00:10<00:00,  5.82it/s]Eval ppl:  95%|█████████▌| 60/63 [00:10<00:00,  5.89it/s]Eval ppl:  97%|█████████▋| 61/63 [00:10<00:00,  5.95it/s]Eval ppl:  98%|█████████▊| 62/63 [00:10<00:00,  5.98it/s]Eval ppl: 100%|██████████| 63/63 [00:11<00:00,  6.06it/s]Eval ppl: 100%|██████████| 63/63 [00:11<00:00,  5.65it/s]
10/29/2022 23:18:31 - INFO - __main__ -     epoch = 0
10/29/2022 23:18:31 - INFO - __main__ -     eval_ppl = 3.68601
10/29/2022 23:18:31 - INFO - __main__ -     global_step = 63
10/29/2022 23:18:31 - INFO - __main__ -     ********************
10/29/2022 23:18:36 - INFO - __main__ -   Save the last model into saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/checkpoint-last/pytorch_model.bin
10/29/2022 23:18:36 - INFO - __main__ -     Best ppl:3.68601
10/29/2022 23:18:36 - INFO - __main__ -     ********************
10/29/2022 23:18:43 - INFO - __main__ -   Save the best ppl model into saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/checkpoint-best-ppl/pytorch_model.bin
10/29/2022 23:18:43 - INFO - __main__ -   ***** CUDA.empty_cache() *****
10/29/2022 23:18:43 - INFO - utils -   Read 500 examples, avg src len: 98, avg trg len: 35, max src len: 622, max trg len: 193
10/29/2022 23:18:43 - INFO - utils -   Sample 5k data for computing bleu from ../data/methods2test/corpus/raw/fm_fc_ms_ff/eval/input.methods.txt,../data/methods2test/corpus/raw/fm_fc_ms_ff/eval/output.tests.txt
  0%|          | 0/500 [00:00<?, ?it/s]  3%|▎         | 16/500 [00:00<00:03, 147.73it/s]  6%|▋         | 32/500 [00:00<00:03, 151.66it/s] 10%|▉         | 48/500 [00:00<00:02, 152.97it/s] 13%|█▎        | 64/500 [00:00<00:02, 153.82it/s] 16%|█▌        | 80/500 [00:00<00:02, 154.39it/s] 19%|█▉        | 96/500 [00:00<00:02, 154.03it/s] 22%|██▏       | 112/500 [00:00<00:02, 154.25it/s] 26%|██▌       | 128/500 [00:00<00:02, 154.35it/s] 29%|██▉       | 144/500 [00:00<00:02, 149.50it/s] 32%|███▏      | 160/500 [00:01<00:02, 150.63it/s] 35%|███▌      | 176/500 [00:01<00:02, 151.36it/s] 38%|███▊      | 192/500 [00:01<00:02, 151.89it/s] 42%|████▏     | 208/500 [00:01<00:01, 151.77it/s] 45%|████▍     | 224/500 [00:01<00:01, 152.31it/s] 48%|████▊     | 240/500 [00:01<00:01, 152.81it/s] 51%|█████     | 256/500 [00:01<00:01, 152.97it/s] 54%|█████▍    | 272/500 [00:01<00:01, 152.44it/s] 58%|█████▊    | 288/500 [00:01<00:01, 152.76it/s] 61%|██████    | 304/500 [00:01<00:01, 152.96it/s] 64%|██████▍   | 320/500 [00:02<00:01, 153.22it/s] 67%|██████▋   | 336/500 [00:02<00:01, 153.12it/s] 70%|███████   | 352/500 [00:02<00:00, 152.05it/s] 74%|███████▎  | 368/500 [00:02<00:00, 152.59it/s] 77%|███████▋  | 384/500 [00:02<00:00, 152.76it/s] 80%|████████  | 400/500 [00:02<00:00, 152.92it/s] 83%|████████▎ | 416/500 [00:02<00:00, 152.52it/s] 86%|████████▋ | 432/500 [00:02<00:00, 152.71it/s] 90%|████████▉ | 448/500 [00:02<00:00, 152.92it/s] 93%|█████████▎| 464/500 [00:03<00:00, 153.04it/s] 96%|█████████▌| 480/500 [00:03<00:00, 153.18it/s] 99%|█████████▉| 496/500 [00:03<00:00, 130.92it/s]100%|██████████| 500/500 [00:03<00:00, 149.99it/s]
10/29/2022 23:18:47 - INFO - __main__ -     ***** Running bleu evaluation on dev data*****
10/29/2022 23:18:47 - INFO - __main__ -     Num examples = 500
10/29/2022 23:18:47 - INFO - __main__ -     Batch size = 8
Eval bleu for dev set:   0%|          | 0/63 [00:00<?, ?it/s]Eval bleu for dev set:   2%|▏         | 1/63 [00:03<03:11,  3.08s/it]Eval bleu for dev set:   3%|▎         | 2/63 [00:05<03:01,  2.98s/it]Eval bleu for dev set:   5%|▍         | 3/63 [00:08<02:58,  2.97s/it]Eval bleu for dev set:   6%|▋         | 4/63 [00:11<02:54,  2.95s/it]Eval bleu for dev set:   8%|▊         | 5/63 [00:14<02:50,  2.94s/it]Eval bleu for dev set:  10%|▉         | 6/63 [00:17<02:45,  2.90s/it]Eval bleu for dev set:  11%|█         | 7/63 [00:20<02:42,  2.91s/it]Eval bleu for dev set:  13%|█▎        | 8/63 [00:23<02:39,  2.91s/it]Eval bleu for dev set:  14%|█▍        | 9/63 [00:26<02:37,  2.91s/it]Eval bleu for dev set:  16%|█▌        | 10/63 [00:29<02:34,  2.91s/it]Eval bleu for dev set:  17%|█▋        | 11/63 [00:32<02:30,  2.89s/it]Eval bleu for dev set:  19%|█▉        | 12/63 [00:35<02:27,  2.90s/it]Eval bleu for dev set:  21%|██        | 13/63 [00:37<02:24,  2.89s/it]Eval bleu for dev set:  22%|██▏       | 14/63 [00:40<02:21,  2.89s/it]Eval bleu for dev set:  24%|██▍       | 15/63 [00:43<02:19,  2.90s/it]Eval bleu for dev set:  25%|██▌       | 16/63 [00:46<02:16,  2.91s/it]Eval bleu for dev set:  27%|██▋       | 17/63 [00:49<02:12,  2.88s/it]Eval bleu for dev set:  29%|██▊       | 18/63 [00:52<02:10,  2.89s/it]Eval bleu for dev set:  30%|███       | 19/63 [00:55<02:07,  2.90s/it]Eval bleu for dev set:  32%|███▏      | 20/63 [00:58<02:04,  2.90s/it]Eval bleu for dev set:  33%|███▎      | 21/63 [01:01<02:02,  2.91s/it]Eval bleu for dev set:  35%|███▍      | 22/63 [01:04<01:59,  2.91s/it]Eval bleu for dev set:  37%|███▋      | 23/63 [01:06<01:56,  2.91s/it]Eval bleu for dev set:  38%|███▊      | 24/63 [01:09<01:54,  2.92s/it]Eval bleu for dev set:  40%|███▉      | 25/63 [01:12<01:50,  2.92s/it]Eval bleu for dev set:  41%|████▏     | 26/63 [01:15<01:48,  2.92s/it]Eval bleu for dev set:  43%|████▎     | 27/63 [01:18<01:44,  2.91s/it]Eval bleu for dev set:  44%|████▍     | 28/63 [01:21<01:42,  2.92s/it]Eval bleu for dev set:  46%|████▌     | 29/63 [01:24<01:39,  2.92s/it]Eval bleu for dev set:  48%|████▊     | 30/63 [01:27<01:36,  2.92s/it]Eval bleu for dev set:  49%|████▉     | 31/63 [01:30<01:33,  2.92s/it]Eval bleu for dev set:  51%|█████     | 32/63 [01:33<01:30,  2.91s/it]Eval bleu for dev set:  52%|█████▏    | 33/63 [01:36<01:27,  2.92s/it]Eval bleu for dev set:  54%|█████▍    | 34/63 [01:39<01:24,  2.92s/it]Eval bleu for dev set:  56%|█████▌    | 35/63 [01:42<01:22,  2.95s/it]Eval bleu for dev set:  57%|█████▋    | 36/63 [01:45<01:19,  2.94s/it]Eval bleu for dev set:  59%|█████▊    | 37/63 [01:48<01:16,  2.96s/it]Eval bleu for dev set:  60%|██████    | 38/63 [01:50<01:13,  2.93s/it]Eval bleu for dev set:  62%|██████▏   | 39/63 [01:53<01:10,  2.93s/it]Eval bleu for dev set:  63%|██████▎   | 40/63 [01:56<01:07,  2.93s/it]Eval bleu for dev set:  65%|██████▌   | 41/63 [01:59<01:04,  2.93s/it]Eval bleu for dev set:  67%|██████▋   | 42/63 [02:02<01:01,  2.93s/it]Eval bleu for dev set:  68%|██████▊   | 43/63 [02:05<00:58,  2.93s/it]Eval bleu for dev set:  70%|██████▉   | 44/63 [02:08<00:55,  2.93s/it]Eval bleu for dev set:  71%|███████▏  | 45/63 [02:11<00:52,  2.93s/it]Eval bleu for dev set:  73%|███████▎  | 46/63 [02:14<00:49,  2.93s/it]Eval bleu for dev set:  75%|███████▍  | 47/63 [02:17<00:46,  2.91s/it]Eval bleu for dev set:  76%|███████▌  | 48/63 [02:20<00:43,  2.92s/it]Eval bleu for dev set:  78%|███████▊  | 49/63 [02:22<00:40,  2.89s/it]Eval bleu for dev set:  79%|███████▉  | 50/63 [02:25<00:37,  2.89s/it]Eval bleu for dev set:  81%|████████  | 51/63 [02:28<00:34,  2.88s/it]Eval bleu for dev set:  83%|████████▎ | 52/63 [02:31<00:31,  2.89s/it]Eval bleu for dev set:  84%|████████▍ | 53/63 [02:34<00:28,  2.88s/it]Eval bleu for dev set:  86%|████████▌ | 54/63 [02:37<00:26,  2.90s/it]Eval bleu for dev set:  87%|████████▋ | 55/63 [02:40<00:23,  2.91s/it]Eval bleu for dev set:  89%|████████▉ | 56/63 [02:43<00:20,  2.91s/it]Eval bleu for dev set:  90%|█████████ | 57/63 [02:46<00:17,  2.91s/it]Eval bleu for dev set:  92%|█████████▏| 58/63 [02:49<00:14,  2.92s/it]Eval bleu for dev set:  94%|█████████▎| 59/63 [02:52<00:11,  2.92s/it]Eval bleu for dev set:  95%|█████████▌| 60/63 [02:54<00:08,  2.92s/it]Eval bleu for dev set:  97%|█████████▋| 61/63 [02:57<00:05,  2.90s/it]Eval bleu for dev set:  98%|█████████▊| 62/63 [03:00<00:02,  2.91s/it]Eval bleu for dev set: 100%|██████████| 63/63 [03:03<00:00,  2.70s/it]Eval bleu for dev set: 100%|██████████| 63/63 [03:03<00:00,  2.90s/it]
10/29/2022 23:22:15 - INFO - __main__ -   ***** Eval results *****
10/29/2022 23:22:15 - INFO - __main__ -     bleu = 0.12
10/29/2022 23:22:15 - INFO - __main__ -     codebleu = 7.707
10/29/2022 23:22:15 - INFO - __main__ -     em = 0.0
10/29/2022 23:22:15 - INFO - __main__ -     [0] Best bleu+em: 0.12 (bleu: 0.12, em: 0.00)
10/29/2022 23:22:15 - INFO - __main__ -     ********************
10/29/2022 23:22:21 - INFO - __main__ -   Save the best bleu model into saved_models/concode/codet5_base_500_lr10_bs8_src320_trg320_10/29/22_23:16:10/checkpoint-best-bleu/pytorch_model.bin
10/29/2022 23:22:21 - INFO - __main__ -   ***** CUDA.empty_cache() *****
10/29/2022 23:22:21 - INFO - __main__ -   Finish training and take 4m
10/29/2022 23:22:21 - INFO - __main__ -   Finish and take 4m
ngram match: 0.0006646292996960978, weighted ngram match: 0.0007455624449379853, syntax_match: 0.08713952325387564, dataflow_match: 0.21972907836782182
============================Start Running==========================
bash exp_with_args.sh concode none codet5_base 0,1,2,3 500 8 10 320 320 3 20 1000 saved_models tensorboard results/concode_codet5_base.txt

